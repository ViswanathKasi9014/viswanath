{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ViswanathKasi9014/viswanath/blob/main/codealpha_task2_Speech_Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'ravdess-emotional-speech-audio:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F107620%2F256618%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240930%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240930T160230Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dc5c0516b3fa54ef81ddaef339367f05d5b3d89714e6ab9095ca26b3613b5a3af4c3d2aefa7ba22143fd1cbae6af6f3f7eea794aa65e2cd0204ecea52fbc828c2ef2b1b2ec15820c975ea4b01b1d961a7200081f80c6d18f24c3e93ec31341a4e2f536055023b0121a96df8aab23b32b898df02898388dce9824f4cb4f014574215f8740d066b4e4922a8826b58453e6467cd9b60012b00b4cabe65315fcd76973c508cc8b33e3d7b6ff5cb68a4aefb0de735ab9e0c2fbad731a1e37b2520a650c6858d248bbabc13192cef03ffb701751d4a03d72df4363a87e07c43552b7339583352ce3c77e393a96dbea2d26282bea6539fcd469519712782875100bd4095,toronto-emotional-speech-set-tess:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F316368%2F639622%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240930%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240930T160230Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3a2e1072850905db72654b01ff920b77dcd619860b1dae5f85683202dd3b3eca50d54fe1527835a6ef52be21688af2bcb337c1dc7df4e59232b1d518a07b25c43420111681efe2e5688702085f8fc890aa127c0dc307d1fe2645f5d75e95a8184a12489ddef0197db92e50b77f2286c3425832dac07322252469c94303391dfe9263e890d0ce1ccfa7b902b76a3ea5ac8cd6045555d5f06d775f226e72467eabef9d4f00f2e6e34c5452fa85c9a490fcef7e0318f85f5216b0c868a46725c6e22f9bd0819204b7615a78f10d45c42f1d7ed93ad8ab3a1c89857b102ef4ef34a7541e2bfa4721ae4751cfc6df824cd49930bbd139414daf1abd662c81554cf7e6,cremad:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F325566%2F653195%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240930%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240930T160230Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D71e5d57fcd2d024b6406221267e42cc3c13c4b39f96023c1d81d485687ac96d34c535048108bd8283220b4b2d6089023aa6c305d68237fd8455dbea2c0e159a10499b45b4cec197f0fee1601381db58be4739e0fe361f85271346bd501187800f1492d06b5b7ac2f72344c3cfd581bcc6c0bd32801ec00eec2f62a40f3d9fea5ec3002a70fd1fe0002243c64f12b4eeaa597ab2ef199727736346c6989657ce413b38b8c1b196f03f4b96165b82f86811556d5377d4fdb2793050413fa2268bc53998feb7b57f3ec56ed67532771f3a514ea779850d6c296b350381a19045c7eab19bc052069bba337f9038f63e2ceefd66ef0e93a596fc68e683755296bfc46,surrey-audiovisual-expressed-emotion-savee:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F338555%2F671851%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240930%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240930T160230Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D58d976f9dd9944834bb397deef26c9e05ac709691f95a76f4b77b7098bd91e71ba49032e96222b17d667e87f8d777b188df11c8aa50e5c7915af886fbb63ac7ee9c6ff4137682aa73483b0ab95518c5da318095683bf8c856c613b89850edda0070f7b5ba4f0fe50f39e4236ee169d2e7757099bb9af766fe7dcd4d39ccfc04f007bfe7ae9f9ece425695c1acd6ecf57be53cb8b5041fb258230882b0d539815af84ae287035599ebc7e1ccd66ea777a34d01ee038b70c19f0ef67c6eb6d20baa8780b5d786e7521619b1f5ff8704c10dbfea706e2ae7e2e30e648769170166476759a2b8c25e4878c49fef2bf110be3c3cfbed0fd3c6a7d4f2305edfdeb303c'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRrpBz8bq07L",
        "outputId": "33642717-94d9-43a2-a280-3f0f24330c7f"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ravdess-emotional-speech-audio, 450102890 bytes compressed\n",
            "[==================================================] 450102890 bytes downloaded\n",
            "Downloaded and uncompressed: ravdess-emotional-speech-audio\n",
            "Downloading toronto-emotional-speech-set-tess, 448572034 bytes compressed\n",
            "[==================================================] 448572034 bytes downloaded\n",
            "Downloaded and uncompressed: toronto-emotional-speech-set-tess\n",
            "Downloading cremad, 473324524 bytes compressed\n",
            "[==================================================] 473324524 bytes downloaded\n",
            "Downloaded and uncompressed: cremad\n",
            "Downloading surrey-audiovisual-expressed-emotion-savee, 112690765 bytes compressed\n",
            "[==================================================] 112690765 bytes downloaded\n",
            "Downloaded and uncompressed: surrey-audiovisual-expressed-emotion-savee\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 88
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "45wl9KEtq07R"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
        "import librosa\n",
        "import librosa.display\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# to play the audio files\n",
        "from IPython.display import Audio\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import warnings\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "5-PJ322uq07S"
      },
      "cell_type": "code",
      "source": [
        "# Paths for data.\n",
        "Ravdess = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\n",
        "Crema = \"/kaggle/input/cremad/AudioWAV/\"\n",
        "Tess = \"/kaggle/input/toronto-emotional-speech-set-tess/tess toronto emotional speech set data/TESS Toronto emotional speech set data/\"\n",
        "Savee = \"/kaggle/input/surrey-audiovisual-expressed-emotion-savee/ALL/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MqoA6CZDq07S",
        "outputId": "8fe8e98d-e8c4-4a32-c671-7fe2de67d98d"
      },
      "cell_type": "code",
      "source": [
        "ravdess_directory_list = os.listdir(Ravdess)\n",
        "\n",
        "file_emotion = []\n",
        "file_path = []\n",
        "for dir in ravdess_directory_list:\n",
        "    # as their are 20 different actors in our previous directory we need to extract files for each actor.\n",
        "    actor = os.listdir(Ravdess + dir)\n",
        "    for file in actor:\n",
        "        part = file.split('.')[0]\n",
        "        part = part.split('-')\n",
        "        # third part in each file represents the emotion associated to that file.\n",
        "        file_emotion.append(int(part[2]))\n",
        "        file_path.append(Ravdess + dir + '/' + file)\n",
        "\n",
        "# dataframe for emotion of files\n",
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "\n",
        "# dataframe for path of files.\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "Ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "\n",
        "# changing integers to actual emotions.\n",
        "Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
        "Ravdess_df.head()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Emotions                                               Path\n",
              "0   disgust  /kaggle/input/ravdess-emotional-speech-audio/a...\n",
              "1  surprise  /kaggle/input/ravdess-emotional-speech-audio/a...\n",
              "2       sad  /kaggle/input/ravdess-emotional-speech-audio/a...\n",
              "3       sad  /kaggle/input/ravdess-emotional-speech-audio/a...\n",
              "4       sad  /kaggle/input/ravdess-emotional-speech-audio/a..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8821d51b-5185-4ce5-8a34-b764c9e4313f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emotions</th>\n",
              "      <th>Path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>disgust</td>\n",
              "      <td>/kaggle/input/ravdess-emotional-speech-audio/a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>surprise</td>\n",
              "      <td>/kaggle/input/ravdess-emotional-speech-audio/a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sad</td>\n",
              "      <td>/kaggle/input/ravdess-emotional-speech-audio/a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sad</td>\n",
              "      <td>/kaggle/input/ravdess-emotional-speech-audio/a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sad</td>\n",
              "      <td>/kaggle/input/ravdess-emotional-speech-audio/a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8821d51b-5185-4ce5-8a34-b764c9e4313f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8821d51b-5185-4ce5-8a34-b764c9e4313f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8821d51b-5185-4ce5-8a34-b764c9e4313f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9883c2ac-f985-4aeb-9aae-bd0ebd40505f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9883c2ac-f985-4aeb-9aae-bd0ebd40505f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9883c2ac-f985-4aeb-9aae-bd0ebd40505f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "Ravdess_df",
              "summary": "{\n  \"name\": \"Ravdess_df\",\n  \"rows\": 1440,\n  \"fields\": [\n    {\n      \"column\": \"Emotions\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"surprise\",\n          \"fear\",\n          \"disgust\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1440,\n        \"samples\": [\n          \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_07/03-01-05-01-01-02-07.wav\",\n          \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_08/03-01-07-01-01-01-08.wav\",\n          \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_01/03-01-06-01-02-01-01.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Dthpj3Flq07T"
      },
      "cell_type": "code",
      "source": [
        "crema_directory_list = os.listdir(Crema)\n",
        "\n",
        "file_emotion = []\n",
        "file_path = []\n",
        "\n",
        "for file in crema_directory_list:\n",
        "    # storing file paths\n",
        "    file_path.append(Crema + file)\n",
        "    # storing file emotions\n",
        "    part=file.split('_')\n",
        "    if part[2] == 'SAD':\n",
        "        file_emotion.append('sad')\n",
        "    elif part[2] == 'ANG':\n",
        "        file_emotion.append('angry')\n",
        "    elif part[2] == 'DIS':\n",
        "        file_emotion.append('disgust')\n",
        "    elif part[2] == 'FEA':\n",
        "        file_emotion.append('fear')\n",
        "    elif part[2] == 'HAP':\n",
        "        file_emotion.append('happy')\n",
        "    elif part[2] == 'NEU':\n",
        "        file_emotion.append('neutral')\n",
        "    else:\n",
        "        file_emotion.append('Unknown')\n",
        "\n",
        "# dataframe for emotion of files\n",
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "\n",
        "# dataframe for path of files.\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "Crema_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "GKJj7LGNq07T"
      },
      "cell_type": "code",
      "source": [
        "tess_directory_list = os.listdir(Tess)\n",
        "\n",
        "file_emotion = []\n",
        "file_path = []\n",
        "\n",
        "for dir in tess_directory_list:\n",
        "    directories = os.listdir(Tess + dir)\n",
        "    for file in directories:\n",
        "        part = file.split('.')[0]\n",
        "        part = part.split('_')[2]\n",
        "        if part=='ps':\n",
        "            file_emotion.append('surprise')\n",
        "        else:\n",
        "            file_emotion.append(part)\n",
        "        file_path.append(Tess + dir + '/' + file)\n",
        "\n",
        "# dataframe for emotion of files\n",
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "\n",
        "# dataframe for path of files.\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "Tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "Tess_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "7qg704r2q07U"
      },
      "cell_type": "code",
      "source": [
        "savee_directory_list = os.listdir(Savee)\n",
        "\n",
        "file_emotion = []\n",
        "file_path = []\n",
        "\n",
        "for file in savee_directory_list:\n",
        "    file_path.append(Savee + file)\n",
        "    part = file.split('_')[1]\n",
        "    ele = part[:-6]\n",
        "    if ele=='a':\n",
        "        file_emotion.append('angry')\n",
        "    elif ele=='d':\n",
        "        file_emotion.append('disgust')\n",
        "    elif ele=='f':\n",
        "        file_emotion.append('fear')\n",
        "    elif ele=='h':\n",
        "        file_emotion.append('happy')\n",
        "    elif ele=='n':\n",
        "        file_emotion.append('neutral')\n",
        "    elif ele=='sa':\n",
        "        file_emotion.append('sad')\n",
        "    else:\n",
        "        file_emotion.append('surprise')\n",
        "\n",
        "# dataframe for emotion of files\n",
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "\n",
        "# dataframe for path of files.\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "Savee_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "Savee_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QugEaME8q07U"
      },
      "cell_type": "code",
      "source": [
        "# creating Dataframe using all the 4 dataframes we created so far.\n",
        "data_path = pd.concat([Ravdess_df, Crema_df, Tess_df, Savee_df], axis = 0)\n",
        "data_path.to_csv(\"data_path.csv\",index=False)\n",
        "data_path.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "MZeYGNKFq07V"
      },
      "cell_type": "code",
      "source": [
        "plt.title('Count of Emotions', size=16)\n",
        "sns.countplot(data_path.Emotions)\n",
        "plt.ylabel('Count', size=12)\n",
        "plt.xlabel('Emotions', size=12)\n",
        "sns.despine(top=True, right=True, left=False, bottom=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "s-do20GGq07V"
      },
      "cell_type": "code",
      "source": [
        "def create_waveplot(data, sr, e):\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.title('waveplot for audio with {} emotion'.format(e), size=15)\n",
        "    librosa.display.waveshow(data, sr=sr)\n",
        "    plt.show()\n",
        "def create_spectrogram(data, sr, e):\n",
        "    # stft function converts the data into short term fourier transform\n",
        "    X = librosa.stft(data)\n",
        "    Xdb = librosa.amplitude_to_db(abs(X))\n",
        "    plt.figure(figsize=(12, 3))\n",
        "    plt.title('Spectrogram for audio with {} emotion'.format(e), size=15)\n",
        "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
        "    #librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n",
        "    plt.colorbar()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Hojxg27fq07W"
      },
      "cell_type": "code",
      "source": [
        "emotion='fear'\n",
        "path = np.array(data_path.Path[data_path.Emotions==emotion])[1]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "create_waveplot(data, sampling_rate, emotion)\n",
        "create_spectrogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pPzgTnNDq07W"
      },
      "cell_type": "code",
      "source": [
        "emotion='angry'\n",
        "path = np.array(data_path.Path[data_path.Emotions==emotion])[1]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "create_waveplot(data, sampling_rate, emotion)\n",
        "create_spectrogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "wZvgjIlfq07W"
      },
      "cell_type": "code",
      "source": [
        "emotion='sad'\n",
        "path = np.array(data_path.Path[data_path.Emotions==emotion])[1]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "create_waveplot(data, sampling_rate, emotion)\n",
        "create_spectrogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Z16N4xIPq07W"
      },
      "cell_type": "code",
      "source": [
        "emotion='happy'\n",
        "path = np.array(data_path.Path[data_path.Emotions==emotion])[1]\n",
        "data, sampling_rate = librosa.load(path)\n",
        "create_waveplot(data, sampling_rate, emotion)\n",
        "create_spectrogram(data, sampling_rate, emotion)\n",
        "Audio(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "5TuUk7f-q07W"
      },
      "cell_type": "code",
      "source": [
        "def noise(data):\n",
        "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
        "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
        "    return data\n",
        "\n",
        "def stretch(data, rate=0.8):\n",
        "    return librosa.effects.time_stretch(data, rate)\n",
        "\n",
        "def shift(data):\n",
        "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
        "    return np.roll(data, shift_range)\n",
        "\n",
        "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
        "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
        "\n",
        "# taking any example and checking for techniques.\n",
        "path = np.array(data_path.Path)[1]\n",
        "data, sample_rate = librosa.load(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "rE4y7EBfq07X"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,4))\n",
        "librosa.display.waveshow(y=data, sr=sample_rate)\n",
        "Audio(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Tup8RUETq07X"
      },
      "cell_type": "code",
      "source": [
        "x = noise(data)\n",
        "plt.figure(figsize=(14,4))\n",
        "librosa.display.waveshow(y=x, sr=sample_rate)\n",
        "Audio(x, rate=sample_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "n810EudXq07X"
      },
      "cell_type": "code",
      "source": [
        "librosa.effects.time_stretch(data, rate=2)\n",
        "plt.figure(figsize=(14,4))\n",
        "librosa.display.waveshow(y=x, sr=sample_rate)\n",
        "Audio(x, rate=sample_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "4bXCh_Hiq07X"
      },
      "cell_type": "code",
      "source": [
        "x = shift(data)\n",
        "plt.figure(figsize=(14,4))\n",
        "librosa.display.waveshow(y=x, sr=sample_rate)\n",
        "Audio(x, rate=sample_rate)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Speech Emotion Recognition",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}